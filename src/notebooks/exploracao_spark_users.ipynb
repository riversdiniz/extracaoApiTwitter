{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==3.3.1 in /home/river/Documentos/airflowalura/venv/lib/python3.9/site-packages (3.3.1)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /home/river/Documentos/airflowalura/venv/lib/python3.9/site-packages (from pyspark==3.3.1) (0.10.9.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark==3.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/16 15:55:01 WARN Utils: Your hostname, river-virtual-machine resolves to a loopback address: 127.0.1.1; using 192.168.133.128 instead (on interface ens33)\n",
      "23/01/16 15:55:01 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/16 15:55:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/01/16 15:55:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"twitter_transformation_users\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"../../../datalake/twitter_datascience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+------------+\n",
      "|                data|            includes|                meta|extract_date|\n",
      "+--------------------+--------------------+--------------------+------------+\n",
      "|[{737142202481016...|{[{2016-05-30T04:...|{1614960801781252...|  2023-01-16|\n",
      "|[{156551075009305...|{[{2022-09-02T01:...|{1614960439531819...|  2023-01-16|\n",
      "|[{161308754706814...|{[{2023-01-11T08:...|{1614960279242276...|  2023-01-16|\n",
      "|[{109402247573690...|{[{2019-02-08T23:...|{1614960021451976...|  2023-01-16|\n",
      "|[{101181765595789...|{[{2018-06-27T03:...|{1614959798633795...|  2023-01-16|\n",
      "|[{137155121135112...|{[{2021-03-15T19:...|{1614959535180898...|  2023-01-16|\n",
      "|[{142970475005707...|{[{2021-08-23T07:...|{1614959337641762...|  2023-01-16|\n",
      "|[{18570502, 16149...|{[{2009-01-03T02:...|{1614959152417079...|  2023-01-16|\n",
      "|[{161308682069857...|{[{2023-01-11T08:...|{1614958997207154...|  2023-01-16|\n",
      "|[{130630626775391...|{[{2020-09-16T18:...|{1614958862225838...|  2023-01-16|\n",
      "|[{156427177422900...|{[{2022-08-29T15:...|{1614958678876258...|  2023-01-16|\n",
      "|[{928368301755064...|{[{2017-11-08T21:...|{1614958516157939...|  2023-01-16|\n",
      "|[{138155154308270...|{[{2021-04-12T10:...|{1614958341955936...|  2023-01-16|\n",
      "|[{912927251926151...|{[{2017-09-27T06:...|{1614958256614690...|  2023-01-16|\n",
      "|[{107705571895873...|{[{2018-12-24T04:...|{1614958148502142...|  2023-01-16|\n",
      "|[{154576577748311...|{[{2022-07-09T13:...|{1614958064699936...|  2023-01-16|\n",
      "|[{140386175480804...|{[{2021-06-12T23:...|{1614957804309061...|  2023-01-16|\n",
      "|[{109402247573690...|{[{2019-02-08T23:...|{1614957462322298...|  2023-01-16|\n",
      "|[{138896364965459...|{[{2021-05-02T21:...|{1614957261566234...|  2023-01-16|\n",
      "|[{435748709, 1614...|{[{2011-12-13T11:...|{1614957128887992...|  2023-01-16|\n",
      "+--------------------+--------------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- data: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- author_id: string (nullable = true)\n",
      " |    |    |-- conversation_id: string (nullable = true)\n",
      " |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |-- edit_history_tweet_ids: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- in_reply_to_user_id: string (nullable = true)\n",
      " |    |    |-- lang: string (nullable = true)\n",
      " |    |    |-- public_metrics: struct (nullable = true)\n",
      " |    |    |    |-- impression_count: long (nullable = true)\n",
      " |    |    |    |-- like_count: long (nullable = true)\n",
      " |    |    |    |-- quote_count: long (nullable = true)\n",
      " |    |    |    |-- reply_count: long (nullable = true)\n",
      " |    |    |    |-- retweet_count: long (nullable = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |-- includes: struct (nullable = true)\n",
      " |    |-- users: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- username: string (nullable = true)\n",
      " |-- meta: struct (nullable = true)\n",
      " |    |-- newest_id: string (nullable = true)\n",
      " |    |-- next_token: string (nullable = true)\n",
      " |    |-- oldest_id: string (nullable = true)\n",
      " |    |-- result_count: long (nullable = true)\n",
      " |-- extract_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[col: struct<created_at:string,id:string,name:string,username:string>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(f.explode(\"includes.users\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[users: struct<created_at:string,id:string,name:string,username:string>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(f.explode(\"includes.users\").alias(\"users\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.explode(\"includes.users\").alias(\"users\")).select(\"users.*\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = df.select(f.explode(\"includes.users\").alias(\"users\")).select(\"users.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+--------------+\n",
      "|          created_at|                 id|                name|      username|\n",
      "+--------------------+-------------------+--------------------+--------------+\n",
      "|2016-05-30T04:42:...| 737142202481016832|     Chidambara .ML.|  chidambara09|\n",
      "|2014-07-04T17:07:...|         2603796666|Annoying Professi...|    StormyCube|\n",
      "|2009-04-08T14:29:...|           29726352|         UKAuthority|   UKAuthority|\n",
      "|2012-04-16T07:55:...|          555031989|     Ronald van Loon|Ronald_vanLoon|\n",
      "|2022-12-29T10:16:...|1608405925886304257|EdTechDigit Innov...|   edtechdigit|\n",
      "+--------------------+-------------------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.coalesce(1).write.mode(\"overwrite\").json('output/tweet')\n",
    "user_df.coalesce(1).write.mode(\"overwrite\").json('output/user')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfbafb487f47b5149b396dfefd775ef48bad4f6f53c0c377dc9b95ba5beb0cf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
